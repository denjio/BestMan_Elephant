""" 
# @Author: Youbin Yao 
# @Date: 2024-09-01 13:24:30
# @Last Modified by:   Youbin Yao 
# @Last Modified time: 2024-09-01 13:24:30  
""" 
import sys
import os
sys.path.append(os.getcwd())
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(parent_dir, 'RoboticsToolBox'))
sys.path.append(os.path.join(parent_dir, 'Visualization'))
import numpy as np
import cv2
import json
from RoboticsToolBox import Bestman_Real_Elephant
from Visualization import calibration_eye_to_hand, Transform
from urdf_parser_py.urdf import URDF
from scipy.spatial.transform import Rotation as R
from ikpy.chain import Chain
from ikpy.link import OriginLink, URDFLink
 
# 读取 JSON 文件中的相机参数
json_file_path = '/home/robot/Desktop/BestMan_Elephant/camera_params.json'
with open(json_file_path, 'r') as file:
    camera_params = json.load(file)

# 提取相机参数
mtx = np.array(camera_params['mtx']).reshape((3, 3))
dist = np.array(camera_params['dist'])
rvecs = np.array(camera_params['rvecs'])
tvecs = np.array(camera_params['tvecs'])

# 假设图像中目标点的像素坐标 (u, v) 和深度 Z
u, v= 200, 150 # 假设中心点
Z = 0.659 # 假设深度为 2 米

# 去畸变并将图像坐标转换为摄像机坐标
undistorted_points = cv2.undistortPoints(np.array([[u, v]], dtype=np.float32), mtx, dist, None, mtx)
print(undistorted_points)
X = (undistorted_points[0][0][0] ) * Z 
Y = (undistorted_points[0][0][1] ) * Z 
P_camera = np.array([X, Y, Z, 1.0])
print(P_camera)

# 加载URDF文件
robot = URDF.from_xml_file('/home/robot/Desktop/BestMan_Elephant/Asset/mycobot_pro_630.urdf')
# print(robot)

end_effort_list=[
[240.712679,9.248801,212.482240,-172.830392,5.296393,75.100849],
[335.795279,-21.471282,225.889988,-175.640753,5.436961,74.837881],
[378.083953,-35.134275,226.980209,-177.597721,5.527260,74.651056],
[425.343435,-50.403095,195.770261,-176.239918,5.465218,74.781119],
[412.554531,-119.542458,195.539676,-176.710241,-1.576748,71.953654],
[359.200694,-103.622610,238.091197,-179.039080,1.580000,70.701836],
[323.969766,-76.018262,240.532579,-178.202566,1.483139,69.975320],
[323.987944,-76.029838,240.543581,-178.454504,1.742036,61.125765],
[292.524264,-59.120198,234.492561,-176.952303,1.757542,61.171618],
[293.878582,-59.848014,202.971447,-170.482091,0.257614,70.691542],
[348.796888,-89.362845,220.694458,-175.671029,1.072112,70.630979],
[392.877077,-113.052851,212.610265,-177.141573,1.301605,70.600573],
[444.974773,-142.783362,209.703691,178.910287,3.564923,69.847746],
[356.301430,124.595652,239.140334,-178.962464,-5.269219,68.445625],
[302.497164,14.873241,226.601324,-171.473388,-7.233345,63.601711],
[369.354653,73.148309,238.939037,178.605093,-1.032620,85.253348],
[375.511970,-15.940784,238.969151,178.373988,2.035370,69.121279],
[375.512559,-15.931280,238.969529,177.960103,1.620950,56.211062],
# [372.494568,-4.742098,229.503567,-174.798854,-8.342979,70.693422], # 18的标定是错的，不要
[302.475687,14.879355,226.596277,-172.377703,-8.182523,70.344853],
]
# 将 end_effort_list 中的所有姿态转换为变换矩阵
R_gripper2base_list = []
t_gripper2base_list = []

for pose in end_effort_list:
    xyz = pose[0:3]
    euler_angles_deg = pose[3:6]
    
    # 将欧拉角从度转换为弧度
    # euler_angles_rad = np.radians(euler_angles_deg)
    
    # 使用scipy将欧拉角转换为旋转矩阵
    rotation_matrix = R.from_euler('xyz', euler_angles_deg).as_matrix()
    
    # 将xyz作为平移向量
    translation_vector = np.array(xyz)
    
    # 添加到列表
    R_gripper2base_list.append(rotation_matrix)
    t_gripper2base_list.append(translation_vector)
# print(R_gripper2base_list, t_gripper2base_list)

# 遍历每个视角的rvecs和tvecs
R_target2cam_list = []
t_target2cam_list = []

for i in range(len(rvecs)):
    # 将旋转向量转换为旋转矩阵
    R_cam2target, _ = cv2.Rodrigues(rvecs[i])
    
    # # 计算标定板相对于相机的姿态
    R_target2cam = R_cam2target.T
    t_target2cam = -np.dot(R_target2cam, tvecs[i])
    
    R_target2cam_list.append(R_target2cam)
    t_target2cam_list.append(t_target2cam)
# print(R_target2cam_list, t_target2cam_list)

# 使用calibrateHandEye进行手眼标定
R_cam2base, t_cam2base = cv2.calibrateHandEye(
    R_gripper2base_list, t_gripper2base_list,
    R_target2cam_list, t_target2cam_list
)
print('R_cam2base', R_cam2base,'t_cam2base', t_cam2base)
# 构造齐次变换矩阵 T_cam2base
T_cam2base = np.eye(4)
T_cam2base[:3, :3] = R_cam2base
T_cam2base[:3, 3] = t_cam2base.flatten()
# 计算点在机械臂基座坐标系下的位置, 将相机坐标系下的点转换到基座坐标系

print(T_cam2base)
point_base = np.dot(T_cam2base, P_camera)
print('point_base', point_base)

# 计算点在机械臂基座坐标系下的位置
x_base, y_base, z_base = point_base[0],point_base[1],point_base[2]

print(f"目标点在机械臂基座坐标系下的位置: ({x_base}, {y_base}, {z_base})")
bestman = Bestman_Real_Elephant("192.168.43.38", 5001)
# bestman.state_on()
bestman.get_current_cartesian()
bestman.get_current_joint_values()
# 定义垂直向下的欧拉角
bestman.set_arm_coords([373.139389, y_base, 250.544752, -171.458040,-7.242349,63.614122], speed=500)
# bestman.set_arm_joint_values([0.0, -120.0, 120.0, -90.0, -90.0, -0.0],speed=500)

bestman.get_current_cartesian()
bestman.get_current_joint_values()
 
 